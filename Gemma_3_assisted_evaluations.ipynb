{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde34852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import socket\n",
    "import subprocess\n",
    "import requests\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fb8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Host and port for Ollama HTTP API\n",
    "\n",
    "HOST = \"127.0.0.1\"\n",
    "PORT = 11434  \n",
    "\n",
    "# File paths\n",
    "\n",
    "INPUT_FILE = 'control_results.json'\n",
    "OUTPUT_FILE = 'control_evaluations_llama.json'\n",
    "\n",
    "# Enable GPU inference if available\n",
    "os.environ['OLLAMA_CUDA'] = '1'\n",
    "\n",
    "\n",
    "# Daemon management functions\n",
    "def ollama_running():\n",
    "    \"\"\"Check if the Ollama daemon is listening on the configured port.\"\"\"\n",
    "    try:\n",
    "        with socket.create_connection((HOST, PORT), timeout=1):\n",
    "            return True\n",
    "    except OSError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def kill_ollama_processes(port=PORT):\n",
    "    \"\"\"Terminate all processes owning the given TCP port (Windows PowerShell).\"\"\"\n",
    "    ps_cmd = [\n",
    "        \"powershell\", \"-Command\",\n",
    "        (\n",
    "            f\"Get-NetTCPConnection -LocalPort {port} |\"\n",
    "            \" Select-Object -ExpandProperty OwningProcess |\"\n",
    "            \" ForEach-Object { Stop-Process -Id $_ -Force }\"\n",
    "        )\n",
    "    ]\n",
    "    subprocess.run(ps_cmd, check=False)\n",
    "\n",
    "\n",
    "def start_daemon():\n",
    "    \"\"\"Kill any leftover listeners and start ollama serve in the background.\"\"\"\n",
    "    kill_ollama_processes()\n",
    "    return subprocess.Popen(\n",
    "        [\"ollama\", \"serve\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Ensure the Ollama daemon is running\n",
    "if not ollama_running():\n",
    "    serve_proc = start_daemon()\n",
    "    print(f\"Starting Ollama daemon (PID {serve_proc.pid})...\")\n",
    "    time.sleep(5)  # Allow the daemon to become ready\n",
    "else:\n",
    "    print(\"Ollama daemon already running.\")\n",
    "\n",
    "\n",
    "# Load data\n",
    "with open(INPUT_FILE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Loaded {len(data)} items from {INPUT_FILE}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "total_items = len(data)\n",
    "\n",
    "\n",
    "def evaluate_item(item, index, total):\n",
    "    \"\"\"Send a prompt to Gemma3:12b via HTTP and return a YES/NO evaluation.\"\"\"\n",
    "    print(f\"Evaluating item {index+1}/{total}: {item['question'][:60]}...\")\n",
    "\n",
    "    # Construct the evaluation prompt\n",
    "    prompt = (\n",
    "        \"Your task is to evaluate the outputs of another model on a QA task. \"\n",
    "        \"Structure is as follows: question, expected answer, model answer.\\n\"\n",
    "        f\"Question: {item['question']}\\n\"\n",
    "        f\"Expected answer: {item['expected_answer']}\\n\"\n",
    "        f\"Model answer: {item['model_answer']}\\n\"\n",
    "        \"Reply in a single word: YES/NO?\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:27b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            f\"http://{HOST}:{PORT}/api/generate\",\n",
    "            json=payload,\n",
    "            timeout=120\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        result_json = resp.json()\n",
    "\n",
    "        \n",
    "        if 'response' in result_json:\n",
    "            text = result_json['response']\n",
    "        else:\n",
    "            text = result_json['choices'][0]['message']['content']\n",
    "\n",
    "        evaluation = text.strip().split()[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error on item {index+1}: {e}\")\n",
    "        evaluation = \"ERROR\"\n",
    "\n",
    "    print(f\"â†’ Got evaluation: {evaluation}\\n\")\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "# Evaluations\n",
    "for idx, item in enumerate(tqdm(data, desc=\"Evaluating QA pairs\", unit=\"pair\")):\n",
    "    eval_result = evaluate_item(item, idx, total_items)\n",
    "    results.append({\n",
    "        'question': item['question'],\n",
    "        'evaluation': eval_result\n",
    "    })\n",
    "\n",
    "# Save results and print accuracy\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"Wrote {len(results)} evaluation results to {OUTPUT_FILE}\")\n",
    "\n",
    "num_yes = sum(1 for r in results if r['evaluation'].upper() == 'YES')\n",
    "accuracy = (num_yes / len(results)) * 100 if results else 0\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
